{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Hyperparameter optimization"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this experiment the hyperparameters of the model will be optimized on cryptocurrency data. The original paper was released with optimized hyperparameters. But because they did not use cryptocurrency data, new experiments will be done for optimizing the model's hyperparameters on cryptocurrency data. This notebook is made to explain the parts of the code of the scripts. For this notebook the experiment on the learning rate is taken as an example."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Imports"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First the necessary modules en scripts are imported."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "from matplotlib.font_manager import json_dump\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import random\n",
    "import os\n",
    "import sys\n",
    "import math\n",
    "from preprocess_data import preprocess\n",
    "\n",
    "WORKDIR_PATH = os.getcwd() + \"/../../\"\n",
    "sys.path.insert(1, WORKDIR_PATH)\n",
    "\n",
    "from base.train_scinet import train_scinet"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Preprocessing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this part the data is being loaded and preprocessed. At first the settings of the preprocessing are defined."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_format=[\"open\",\"high\",\"low\",\"close\",\"Volume BTC\",\"Volume USDT\",\"tradecount\"]\n",
    "                    \n",
    "fraction_used = 1\n",
    "train_frac = 0.6\n",
    "val_frac = 0.2\n",
    "test_frac = 0.2\n",
    "\n",
    "X_LEN = 48\n",
    "Y_LEN = 24\n",
    "RANDOM_SEED = 4321#None\n",
    "OVERLAPPING = True\n",
    "STANDARDIZE = True\n",
    "\n",
    "standardization_settings = {'per_sample': True,\n",
    "                            'leaky': False,\n",
    "                            'mode': 'log', #only if per sample is false, choose from log, sqrt or lin\n",
    "                            'sqrt_val': 2, #of course only if mode is sqrt\n",
    "                            'total mean': [],\n",
    "                            'total std': []}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Then the dataset is loaded, splitted in samples and train/test sets, and the samples are being normalized."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting data preprocessing...\n",
      "   48740.22  48745.96  48727.47  48727.47.1   2.27206  110730.9135  136.0\n",
      "0  48763.11  48763.12  48736.70    48736.73   5.33108  259880.1205  427.0\n",
      "1  48778.58  48778.58  48750.37    48763.12   6.87389  335219.0368  389.0\n",
      "2  48760.37  48778.58  48746.39    48778.58  10.58951  516291.2896  425.0\n",
      "3  48799.99  48800.00  48756.93    48760.37  12.24525  597357.8390  535.0\n",
      "4  48795.99  48800.00  48795.99    48800.00   7.55759  368810.1891  423.0 (49997, 7)\n",
      "Making train/validation/test splits...\n",
      "Making samples...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████| 29926/29926 [00:32<00:00, 933.44it/s]\n",
      "/Users/lindsayspoor/Library/Mobile Documents/com~apple~CloudDocs/Documents/Studiedocumenten/2021-2022/ADL/SCINet_repo/exp/hyperparams/preprocess_data.py:138: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.\n",
      "  samples = np.array(samples)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Making samples...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████| 9927/9927 [00:12<00:00, 764.35it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Making samples...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████| 9928/9928 [00:10<00:00, 981.23it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Making X-y splits...\n"
     ]
    }
   ],
   "source": [
    "pairs = [\"HUFL\", \"HULL\", \"MUFL\", \"MULL\", \"LUFL\", \"LULL\", \"OT\"]\n",
    "\n",
    "#df = pd.read_csv(os.path.realpath(__file__) + f\"/../data/Data_preprocessed/ETTh1.csv\").dropna()\n",
    "df = pd.read_csv(os.getcwd() + \"/data/Binance_BTCUSDT_minute.csv\").dropna()\n",
    "df = df.swapaxes(\"index\", \"columns\")\n",
    "\n",
    "data = {} \n",
    "for idx, pair in enumerate(pairs):\n",
    "    data[pair] = df.iloc[idx]\n",
    " \n",
    "results = preprocess(   data = data, \n",
    "                        symbols = pairs,\n",
    "                        data_format = data_format,\n",
    "                        fraction = fraction_used,\n",
    "                        train_frac = train_frac,\n",
    "                        val_frac = val_frac,\n",
    "                        test_frac = test_frac,\n",
    "                        X_LEN = X_LEN,\n",
    "                        Y_LEN = Y_LEN,\n",
    "                        OVERLAPPING = OVERLAPPING,\n",
    "                        STANDARDIZE = STANDARDIZE,\n",
    "                        standardization_settings = standardization_settings\n",
    "                        )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Then the model can be trained. At first the hyperparameters which are not being optimized are defined."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "EPOCHS = 10\n",
    "BATCH_SIZE = 8\n",
    "HID_SIZE = 4\n",
    "NUM_LEVELS = 3\n",
    "KERNEL_SIZE = 5\n",
    "DROPOUT = 0.5\n",
    "PROBABILISTIC = False"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Then some values of the parameter to be tuned (in this case the learning rate) are defined. For each value of this parameter a model is trained and it's performance on the validation set is saved for plotting later on."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "===========================[SCINET]=====================================\n",
      "Initializing training with data:\n",
      "X_train: (29926, 48, 7), y_train: (29926, 24, 7)\n",
      "X_val: (9927, 48, 7), y_val: (9927, 24, 7)\n",
      "X_test: (9928, 48, 7), y_test: (9928, 24, 7)\n",
      "Building model...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-06-23 13:26:31.816386: I tensorflow/core/platform/cpu_feature_guard.cc:142] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_1 (InputLayer)         [(None, 48, 7)]           0         \n",
      "_________________________________________________________________\n",
      "Block_0 (SCINet)             (None, 24, 7)             97332     \n",
      "=================================================================\n",
      "Total params: 97,332\n",
      "Trainable params: 97,332\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n",
      "Is null X: 0\n",
      "Is null y: 0\n",
      "Epoch 1/10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-06-23 13:26:35.591645: I tensorflow/compiler/mlir/mlir_graph_optimization_pass.cc:185] None of the MLIR Optimization Passes are enabled (registered 2)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3741/3741 [==============================] - 128s 28ms/step - loss: 1.5126 - val_loss: 1.6476\n",
      "Epoch 2/10\n",
      "3741/3741 [==============================] - 101s 27ms/step - loss: 1.5440 - val_loss: 1.4784\n",
      "Epoch 3/10\n",
      "3741/3741 [==============================] - 111s 30ms/step - loss: 1.5642 - val_loss: 1.4701\n",
      "Epoch 4/10\n",
      "3741/3741 [==============================] - 121s 32ms/step - loss: 1.5165 - val_loss: 1.5331\n",
      "Epoch 5/10\n",
      "3741/3741 [==============================] - 120s 32ms/step - loss: 1.5521 - val_loss: 1.5013\n",
      "Epoch 6/10\n",
      "3741/3741 [==============================] - 117s 31ms/step - loss: 1.5902 - val_loss: 1.4738\n",
      "Epoch 7/10\n",
      "3741/3741 [==============================] - 114s 31ms/step - loss: 1.5575 - val_loss: 1.6858\n",
      "Epoch 8/10\n",
      "3741/3741 [==============================] - 115s 31ms/step - loss: 1.6259 - val_loss: 1.5474\n",
      "Epoch 9/10\n",
      "3741/3741 [==============================] - 118s 32ms/step - loss: 1.5690 - val_loss: 1.4900\n",
      "Epoch 10/10\n",
      "3741/3741 [==============================] - 116s 31ms/step - loss: 1.5220 - val_loss: 1.4566\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-06-23 13:46:14.910645: W tensorflow/python/util/util.cc:348] Sets are not currently considered sequences, but this may change in the future, so consider avoiding using them.\n",
      "WARNING:absl:Found untraced functions such as sci_net__tree_layer_call_and_return_conditional_losses, sci_net__tree_layer_call_fn, conv1d_120_layer_call_and_return_conditional_losses, conv1d_120_layer_call_fn, sci_block_layer_call_and_return_conditional_losses while saving (showing 5 of 1955). These functions will not be directly callable after loading.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: saved_models/model_learning_rate_0.1/assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: saved_models/model_learning_rate_0.1/assets\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "===========================[SCINET]=====================================\n",
      "Initializing training with data:\n",
      "X_train: (29926, 48, 7), y_train: (29926, 24, 7)\n",
      "X_val: (9927, 48, 7), y_val: (9927, 24, 7)\n",
      "X_test: (9928, 48, 7), y_test: (9928, 24, 7)\n",
      "Building model...\n",
      "Model: \"model_1\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_2 (InputLayer)         [(None, 48, 7)]           0         \n",
      "_________________________________________________________________\n",
      "Block_0 (SCINet)             (None, 24, 7)             97332     \n",
      "=================================================================\n",
      "Total params: 97,332\n",
      "Trainable params: 97,332\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n",
      "Is null X: 0\n",
      "Is null y: 0\n",
      "Epoch 1/10\n",
      "3741/3741 [==============================] - 121s 26ms/step - loss: 1.1627 - val_loss: 1.1578\n",
      "Epoch 2/10\n",
      "3741/3741 [==============================] - 107s 29ms/step - loss: 1.1525 - val_loss: 1.1493\n",
      "Epoch 3/10\n",
      "3741/3741 [==============================] - 111s 30ms/step - loss: 1.1497 - val_loss: 1.1616\n",
      "Epoch 4/10\n",
      "3741/3741 [==============================] - 117s 31ms/step - loss: 1.1471 - val_loss: 1.1491\n",
      "Epoch 5/10\n",
      "3741/3741 [==============================] - 112s 30ms/step - loss: 1.1529 - val_loss: 1.1634\n",
      "Epoch 6/10\n",
      "3741/3741 [==============================] - 120s 32ms/step - loss: 1.1536 - val_loss: 1.1549\n",
      "Epoch 7/10\n",
      "3741/3741 [==============================] - 122s 33ms/step - loss: 1.1558 - val_loss: 1.1712\n",
      "Epoch 8/10\n",
      "3741/3741 [==============================] - 124s 33ms/step - loss: 1.1546 - val_loss: 1.1683\n",
      "Epoch 9/10\n",
      "3741/3741 [==============================] - 133s 36ms/step - loss: 1.1513 - val_loss: 1.1576\n",
      "Epoch 10/10\n",
      "3741/3741 [==============================] - 127s 34ms/step - loss: 1.1497 - val_loss: 1.1542\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Found untraced functions such as sci_net__tree_15_layer_call_and_return_conditional_losses, sci_net__tree_15_layer_call_fn, conv1d_241_layer_call_and_return_conditional_losses, conv1d_241_layer_call_fn, sci_block_15_layer_call_and_return_conditional_losses while saving (showing 5 of 1955). These functions will not be directly callable after loading.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: saved_models/model_learning_rate_0.01/assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: saved_models/model_learning_rate_0.01/assets\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "===========================[SCINET]=====================================\n",
      "Initializing training with data:\n",
      "X_train: (29926, 48, 7), y_train: (29926, 24, 7)\n",
      "X_val: (9927, 48, 7), y_val: (9927, 24, 7)\n",
      "X_test: (9928, 48, 7), y_test: (9928, 24, 7)\n",
      "Building model...\n",
      "Model: \"model_2\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_3 (InputLayer)         [(None, 48, 7)]           0         \n",
      "_________________________________________________________________\n",
      "Block_0 (SCINet)             (None, 24, 7)             97332     \n",
      "=================================================================\n",
      "Total params: 97,332\n",
      "Trainable params: 97,332\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n",
      "Is null X: 0\n",
      "Is null y: 0\n",
      "Epoch 1/10\n",
      "3741/3741 [==============================] - 139s 31ms/step - loss: 1.1190 - val_loss: 1.0103\n",
      "Epoch 2/10\n",
      "3741/3741 [==============================] - 111s 30ms/step - loss: 0.9869 - val_loss: 1.0052\n",
      "Epoch 3/10\n",
      "3741/3741 [==============================] - 112s 30ms/step - loss: 0.9624 - val_loss: 0.9853\n",
      "Epoch 4/10\n",
      "3741/3741 [==============================] - 124s 33ms/step - loss: 0.9478 - val_loss: 1.0292\n",
      "Epoch 5/10\n",
      "3741/3741 [==============================] - 123s 33ms/step - loss: 0.9376 - val_loss: 0.9908\n",
      "Epoch 6/10\n",
      "3741/3741 [==============================] - 147s 39ms/step - loss: 0.9292 - val_loss: 0.9853\n",
      "Epoch 7/10\n",
      "3741/3741 [==============================] - 151s 40ms/step - loss: 0.9224 - val_loss: 1.0007\n",
      "Epoch 8/10\n",
      "3741/3741 [==============================] - 139s 37ms/step - loss: 0.9189 - val_loss: 0.9895\n",
      "Epoch 9/10\n",
      "3741/3741 [==============================] - 138s 37ms/step - loss: 0.9155 - val_loss: 1.0009\n",
      "Epoch 10/10\n",
      "3741/3741 [==============================] - 127s 34ms/step - loss: 0.9101 - val_loss: 1.0029\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Found untraced functions such as sci_net__tree_30_layer_call_and_return_conditional_losses, sci_net__tree_30_layer_call_fn, conv1d_362_layer_call_and_return_conditional_losses, conv1d_362_layer_call_fn, sci_block_30_layer_call_and_return_conditional_losses while saving (showing 5 of 1955). These functions will not be directly callable after loading.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: saved_models/model_learning_rate_0.001/assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: saved_models/model_learning_rate_0.001/assets\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "===========================[SCINET]=====================================\n",
      "Initializing training with data:\n",
      "X_train: (29926, 48, 7), y_train: (29926, 24, 7)\n",
      "X_val: (9927, 48, 7), y_val: (9927, 24, 7)\n",
      "X_test: (9928, 48, 7), y_test: (9928, 24, 7)\n",
      "Building model...\n",
      "Model: \"model_3\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_4 (InputLayer)         [(None, 48, 7)]           0         \n",
      "_________________________________________________________________\n",
      "Block_0 (SCINet)             (None, 24, 7)             97332     \n",
      "=================================================================\n",
      "Total params: 97,332\n",
      "Trainable params: 97,332\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n",
      "Is null X: 0\n",
      "Is null y: 0\n",
      "Epoch 1/10\n",
      "3741/3741 [==============================] - 131s 28ms/step - loss: 1.6149 - val_loss: 1.2388\n",
      "Epoch 2/10\n",
      "3741/3741 [==============================] - 82s 22ms/step - loss: 1.1550 - val_loss: 1.0837\n",
      "Epoch 3/10\n",
      "3741/3741 [==============================] - 84s 23ms/step - loss: 1.0510 - val_loss: 1.0359\n",
      "Epoch 4/10\n",
      "3741/3741 [==============================] - 84s 23ms/step - loss: 1.0164 - val_loss: 1.0216\n",
      "Epoch 5/10\n",
      "3741/3741 [==============================] - 82s 22ms/step - loss: 0.9967 - val_loss: 0.9992\n",
      "Epoch 6/10\n",
      "3741/3741 [==============================] - 98s 26ms/step - loss: 0.9816 - val_loss: 1.0016\n",
      "Epoch 7/10\n",
      "3741/3741 [==============================] - 102s 27ms/step - loss: 0.9727 - val_loss: 0.9918\n",
      "Epoch 8/10\n",
      "3741/3741 [==============================] - 90s 24ms/step - loss: 0.9627 - val_loss: 0.9900\n",
      "Epoch 9/10\n",
      "3741/3741 [==============================] - 81s 22ms/step - loss: 0.9577 - val_loss: 0.9826\n",
      "Epoch 10/10\n",
      "3741/3741 [==============================] - 93s 25ms/step - loss: 0.9493 - val_loss: 0.9806\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Found untraced functions such as sci_net__tree_45_layer_call_and_return_conditional_losses, sci_net__tree_45_layer_call_fn, conv1d_483_layer_call_and_return_conditional_losses, conv1d_483_layer_call_fn, sci_block_45_layer_call_and_return_conditional_losses while saving (showing 5 of 1955). These functions will not be directly callable after loading.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: saved_models/model_learning_rate_0.0001/assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: saved_models/model_learning_rate_0.0001/assets\n"
     ]
    }
   ],
   "source": [
    "LEARNING_RATES = [0.1, 0.01, 0.001, 0.0001]\n",
    "\n",
    "train_losses = np.zeros((len(LEARNING_RATES), EPOCHS))\n",
    "val_losses = np.zeros((len(LEARNING_RATES), EPOCHS))\n",
    "for idx, LEARNING_RATE in enumerate(LEARNING_RATES):\n",
    "\n",
    "    model, history, X_train , y_train, X_val, y_val, X_test, y_test = train_scinet( X_train = results[\"X_train\"].astype('float32'),\n",
    "                                                                                    y_train = results[\"y_train\"].astype('float32'),\n",
    "                                                                                    X_val = results[\"X_val\"].astype('float32'),\n",
    "                                                                                    y_val = results[\"y_val\"].astype('float32'),\n",
    "                                                                                    X_test = results[\"X_test\"].astype('float32'),\n",
    "                                                                                    y_test = results[\"y_test\"].astype('float32'),\n",
    "                                                                                    epochs = EPOCHS,\n",
    "                                                                                    batch_size = BATCH_SIZE,\n",
    "                                                                                    X_LEN = X_LEN,\n",
    "                                                                                    Y_LEN = [Y_LEN],\n",
    "                                                                                    output_dim = [results[\"X_train\"].shape[2]],\n",
    "                                                                                    selected_columns = None,\n",
    "                                                                                    hid_size= HID_SIZE,\n",
    "                                                                                    num_levels= NUM_LEVELS,\n",
    "                                                                                    kernel = KERNEL_SIZE,\n",
    "                                                                                    dropout = DROPOUT,\n",
    "                                                                                    loss_weights= [1],\n",
    "                                                                                    learning_rate = LEARNING_RATE,\n",
    "                                                                                    probabilistic = PROBABILISTIC)\n",
    "\n",
    "    train_loss = history.history['loss']\n",
    "    train_losses[idx] = train_loss\n",
    "\n",
    "    val_loss = history.history['val_loss']\n",
    "    val_losses[idx] = val_loss\n",
    "    \n",
    "    model.save(f'saved_models/model_learning_rate_{LEARNING_RATE}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Plotting"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here the performance of each model on the validation set is compared using a plot. The hyperparamer of the model with the lowest loss in the validation set can be selected as the optimal value."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:matplotlib.legend:No handles with labels found to put in legend.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1.6475629806518555, 1.1578296422958374, 1.0103024244308472, 1.2387771606445312]\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "\n",
    "from utils.plotting import plot_barplot\n",
    "\n",
    "\n",
    "hyperparameter_type='LearningRate'\n",
    "\n",
    "\n",
    "\n",
    "plot_barplot(LEARNING_RATES, val_losses, hyperparameter_type)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.12"
  },
  "vscode": {
   "interpreter": {
    "hash": "e0d398e7c3cc3d2b8386dfea47f5eae3378d5d39db7e2c8ef87e93246db0bfd2"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
