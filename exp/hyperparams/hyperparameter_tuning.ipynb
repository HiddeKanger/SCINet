{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Hyperparameter optimization"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this experiment the hyperparameters of the model will be optimized on cryptocurrency data. The original paper was released with optimized hyperparameters. But because they did not use cryptocurrency data, new experiments will be done for optimizing the model's hyperparameters on cryptocurrency data. This notebook is made to explain the parts of the code of the scripts. For this notebook the experiment on the learning rate is taken as an example."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Imports"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First the necessary modules en scripts are imported."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from matplotlib.font_manager import json_dump\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import random\n",
    "import os\n",
    "import sys\n",
    "import math\n",
    "from preprocess_data import preprocess\n",
    "\n",
    "WORKDIR_PATH = os.getcwd() + \"/../../\"\n",
    "sys.path.insert(1, WORKDIR_PATH)\n",
    "\n",
    "from base.train_scinet import train_scinet"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Preprocessing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this part the data is being loaded and preprocessed. At first the settings of the preprocessing are defined."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_format=[\"open\",\"high\",\"low\",\"close\",\"Volume BTC\",\"Volume USDT\",\"tradecount\"]\n",
    "                    \n",
    "fraction_used = 1\n",
    "train_frac = 0.6\n",
    "val_frac = 0.2\n",
    "test_frac = 0.2\n",
    "\n",
    "X_LEN = 48\n",
    "Y_LEN = 24\n",
    "RANDOM_SEED = 4321#None\n",
    "OVERLAPPING = True\n",
    "STANDARDIZE = True\n",
    "\n",
    "standardization_settings = {'per_sample': True,\n",
    "                            'leaky': False,\n",
    "                            'mode': 'log', #only if per sample is false, choose from log, sqrt or lin\n",
    "                            'sqrt_val': 2, #of course only if mode is sqrt\n",
    "                            'total mean': [],\n",
    "                            'total std': []}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Then the dataset is loaded, splitted in samples and train/test sets, and the samples are being normalized."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting data preprocessing...\n",
      "   48740.22  48745.96  48727.47  48727.47.1   2.27206  110730.9135  136.0\n",
      "0  48763.11  48763.12  48736.70    48736.73   5.33108  259880.1205  427.0\n",
      "1  48778.58  48778.58  48750.37    48763.12   6.87389  335219.0368  389.0\n",
      "2  48760.37  48778.58  48746.39    48778.58  10.58951  516291.2896  425.0\n",
      "3  48799.99  48800.00  48756.93    48760.37  12.24525  597357.8390  535.0\n",
      "4  48795.99  48800.00  48795.99    48800.00   7.55759  368810.1891  423.0 (49997, 7)\n",
      "Making train/validation/test splits...\n",
      "Making samples...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████████████| 29926/29926 [00:23<00:00, 1251.49it/s]\n",
      "/Users/lindsayspoor/Library/Mobile Documents/com~apple~CloudDocs/Documents/Studiedocumenten/2021-2022/ADL/SCINet_repo/exp/hyperparams/preprocess_data.py:138: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.\n",
      "  samples = np.array(samples)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Making samples...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████| 9927/9927 [00:07<00:00, 1325.98it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Making samples...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████| 9928/9928 [00:08<00:00, 1206.75it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Making X-y splits...\n"
     ]
    }
   ],
   "source": [
    "pairs = [\"HUFL\", \"HULL\", \"MUFL\", \"MULL\", \"LUFL\", \"LULL\", \"OT\"]\n",
    "\n",
    "#df = pd.read_csv(os.path.realpath(__file__) + f\"/../data/Data_preprocessed/ETTh1.csv\").dropna()\n",
    "df = pd.read_csv(os.getcwd() + \"/data/Binance_BTCUSDT_minute.csv\").dropna()\n",
    "df = df.swapaxes(\"index\", \"columns\")\n",
    "\n",
    "data = {} \n",
    "for idx, pair in enumerate(pairs):\n",
    "    data[pair] = df.iloc[idx]\n",
    " \n",
    "results = preprocess(   data = data, \n",
    "                        symbols = pairs,\n",
    "                        data_format = data_format,\n",
    "                        fraction = fraction_used,\n",
    "                        train_frac = train_frac,\n",
    "                        val_frac = val_frac,\n",
    "                        test_frac = test_frac,\n",
    "                        X_LEN = X_LEN,\n",
    "                        Y_LEN = Y_LEN,\n",
    "                        OVERLAPPING = OVERLAPPING,\n",
    "                        STANDARDIZE = STANDARDIZE,\n",
    "                        standardization_settings = standardization_settings\n",
    "                        )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Then the model can be trained. At first the hyperparameters which are not being optimized are defined."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "EPOCHS = 10\n",
    "BATCH_SIZE = 8\n",
    "HID_SIZE = 4\n",
    "NUM_LEVELS = 3\n",
    "KERNEL_SIZE = 5\n",
    "DROPOUT = 0.5\n",
    "PROBABILISTIC = False"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Then some values of the parameter to be tuned (in this case the learning rate) are defined. For each value of this parameter a model is trained and it's performance on the validation set is saved for plotting later on."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "===========================[SCINET]=====================================\n",
      "Initializing training with data:\n",
      "X_train: (29926, 48, 7), y_train: (29926, 24, 7)\n",
      "X_val: (9927, 48, 7), y_val: (9927, 24, 7)\n",
      "X_test: (9928, 48, 7), y_test: (9928, 24, 7)\n",
      "Building model...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-06-23 11:41:04.781569: I tensorflow/core/platform/cpu_feature_guard.cc:142] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_1 (InputLayer)         [(None, 48, 7)]           0         \n",
      "_________________________________________________________________\n",
      "Block_0 (SCINet)             (None, 24, 7)             97332     \n",
      "=================================================================\n",
      "Total params: 97,332\n",
      "Trainable params: 97,332\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n",
      "Is null X: 0\n",
      "Is null y: 0\n",
      "Epoch 1/10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-06-23 11:41:07.055162: I tensorflow/compiler/mlir/mlir_graph_optimization_pass.cc:185] None of the MLIR Optimization Passes are enabled (registered 2)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3741/3741 [==============================] - 126s 29ms/step - loss: 1.5101 - val_loss: 1.5656\n",
      "Epoch 2/10\n",
      "3741/3741 [==============================] - 97s 26ms/step - loss: 1.5497 - val_loss: 1.5485\n",
      "Epoch 3/10\n",
      "3741/3741 [==============================] - 99s 27ms/step - loss: 1.5736 - val_loss: 1.5277\n",
      "Epoch 4/10\n",
      "3741/3741 [==============================] - 98s 26ms/step - loss: 1.5584 - val_loss: 1.4476\n",
      "Epoch 5/10\n",
      "3741/3741 [==============================] - 103s 28ms/step - loss: 1.5129 - val_loss: 1.5305\n",
      "Epoch 6/10\n",
      "3741/3741 [==============================] - 103s 27ms/step - loss: 1.5693 - val_loss: 1.6152\n",
      "Epoch 7/10\n",
      "3741/3741 [==============================] - 95s 25ms/step - loss: 1.6144 - val_loss: 1.6312\n",
      "Epoch 8/10\n",
      "3741/3741 [==============================] - 85s 23ms/step - loss: 1.7115 - val_loss: 1.7257\n",
      "Epoch 9/10\n",
      "3741/3741 [==============================] - 102s 27ms/step - loss: 1.6596 - val_loss: 1.5676\n",
      "Epoch 10/10\n",
      "3741/3741 [==============================] - 104s 28ms/step - loss: 1.5845 - val_loss: 1.5090\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-06-23 11:58:12.346698: W tensorflow/python/util/util.cc:348] Sets are not currently considered sequences, but this may change in the future, so consider avoiding using them.\n",
      "WARNING:absl:Found untraced functions such as sci_net__tree_layer_call_and_return_conditional_losses, sci_net__tree_layer_call_fn, conv1d_120_layer_call_and_return_conditional_losses, conv1d_120_layer_call_fn, sci_block_layer_call_and_return_conditional_losses while saving (showing 5 of 1955). These functions will not be directly callable after loading.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: saved_models/model_learning_rate_0.1/assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: saved_models/model_learning_rate_0.1/assets\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "===========================[SCINET]=====================================\n",
      "Initializing training with data:\n",
      "X_train: (29926, 48, 7), y_train: (29926, 24, 7)\n",
      "X_val: (9927, 48, 7), y_val: (9927, 24, 7)\n",
      "X_test: (9928, 48, 7), y_test: (9928, 24, 7)\n",
      "Building model...\n",
      "Model: \"model_1\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_2 (InputLayer)         [(None, 48, 7)]           0         \n",
      "_________________________________________________________________\n",
      "Block_0 (SCINet)             (None, 24, 7)             97332     \n",
      "=================================================================\n",
      "Total params: 97,332\n",
      "Trainable params: 97,332\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n",
      "Is null X: 0\n",
      "Is null y: 0\n",
      "Epoch 1/10\n",
      "3741/3741 [==============================] - 128s 28ms/step - loss: 1.1645 - val_loss: 1.1593\n",
      "Epoch 2/10\n",
      "3741/3741 [==============================] - 107s 29ms/step - loss: 1.1585 - val_loss: 1.1548\n",
      "Epoch 3/10\n",
      "3741/3741 [==============================] - 112s 30ms/step - loss: 1.1560 - val_loss: 1.1653\n",
      "Epoch 4/10\n",
      "3741/3741 [==============================] - 115s 31ms/step - loss: 1.1503 - val_loss: 1.1569\n",
      "Epoch 5/10\n",
      "3741/3741 [==============================] - 109s 29ms/step - loss: 1.1481 - val_loss: 1.1641\n",
      "Epoch 6/10\n",
      "3741/3741 [==============================] - 85s 23ms/step - loss: 1.1457 - val_loss: 1.1334\n",
      "Epoch 7/10\n",
      "3741/3741 [==============================] - 111s 30ms/step - loss: 1.1448 - val_loss: 1.1457\n",
      "Epoch 8/10\n",
      "3741/3741 [==============================] - 129s 35ms/step - loss: 1.1429 - val_loss: 1.1285\n",
      "Epoch 9/10\n",
      "3741/3741 [==============================] - 108s 29ms/step - loss: 1.1427 - val_loss: 1.1371\n",
      "Epoch 10/10\n",
      "3741/3741 [==============================] - 129s 35ms/step - loss: 1.1431 - val_loss: 1.1382\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Found untraced functions such as sci_net__tree_15_layer_call_and_return_conditional_losses, sci_net__tree_15_layer_call_fn, conv1d_241_layer_call_and_return_conditional_losses, conv1d_241_layer_call_fn, sci_block_15_layer_call_and_return_conditional_losses while saving (showing 5 of 1955). These functions will not be directly callable after loading.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: saved_models/model_learning_rate_0.01/assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: saved_models/model_learning_rate_0.01/assets\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "===========================[SCINET]=====================================\n",
      "Initializing training with data:\n",
      "X_train: (29926, 48, 7), y_train: (29926, 24, 7)\n",
      "X_val: (9927, 48, 7), y_val: (9927, 24, 7)\n",
      "X_test: (9928, 48, 7), y_test: (9928, 24, 7)\n",
      "Building model...\n",
      "Model: \"model_2\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_3 (InputLayer)         [(None, 48, 7)]           0         \n",
      "_________________________________________________________________\n",
      "Block_0 (SCINet)             (None, 24, 7)             97332     \n",
      "=================================================================\n",
      "Total params: 97,332\n",
      "Trainable params: 97,332\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n",
      "Is null X: 0\n",
      "Is null y: 0\n",
      "Epoch 1/10\n",
      "3741/3741 [==============================] - 164s 37ms/step - loss: 1.1269 - val_loss: 1.0116\n",
      "Epoch 2/10\n",
      "3741/3741 [==============================] - 128s 34ms/step - loss: 0.9929 - val_loss: 0.9968\n",
      "Epoch 3/10\n",
      "3741/3741 [==============================] - 129s 35ms/step - loss: 0.9710 - val_loss: 0.9927\n",
      "Epoch 4/10\n",
      "3741/3741 [==============================] - 122s 33ms/step - loss: 0.9572 - val_loss: 0.9942\n",
      "Epoch 5/10\n",
      "3741/3741 [==============================] - 124s 33ms/step - loss: 0.9446 - val_loss: 0.9867\n",
      "Epoch 6/10\n",
      "3741/3741 [==============================] - 93s 25ms/step - loss: 0.9371 - val_loss: 0.9848\n",
      "Epoch 7/10\n",
      "3741/3741 [==============================] - 121s 32ms/step - loss: 0.9304 - val_loss: 0.9934\n",
      "Epoch 8/10\n",
      "3741/3741 [==============================] - 128s 34ms/step - loss: 0.9267 - val_loss: 0.9813\n",
      "Epoch 9/10\n",
      "3741/3741 [==============================] - 120s 32ms/step - loss: 0.9210 - val_loss: 0.9922\n",
      "Epoch 10/10\n",
      "3741/3741 [==============================] - 120s 32ms/step - loss: 0.9163 - val_loss: 0.9959\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Found untraced functions such as sci_net__tree_30_layer_call_and_return_conditional_losses, sci_net__tree_30_layer_call_fn, conv1d_362_layer_call_and_return_conditional_losses, conv1d_362_layer_call_fn, sci_block_30_layer_call_and_return_conditional_losses while saving (showing 5 of 1955). These functions will not be directly callable after loading.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: saved_models/model_learning_rate_0.001/assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: saved_models/model_learning_rate_0.001/assets\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "===========================[SCINET]=====================================\n",
      "Initializing training with data:\n",
      "X_train: (29926, 48, 7), y_train: (29926, 24, 7)\n",
      "X_val: (9927, 48, 7), y_val: (9927, 24, 7)\n",
      "X_test: (9928, 48, 7), y_test: (9928, 24, 7)\n",
      "Building model...\n",
      "Model: \"model_3\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_4 (InputLayer)         [(None, 48, 7)]           0         \n",
      "_________________________________________________________________\n",
      "Block_0 (SCINet)             (None, 24, 7)             97332     \n",
      "=================================================================\n",
      "Total params: 97,332\n",
      "Trainable params: 97,332\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n",
      "Is null X: 0\n",
      "Is null y: 0\n",
      "Epoch 1/10\n",
      "3741/3741 [==============================] - 140s 31ms/step - loss: 1.7047 - val_loss: 1.2505\n",
      "Epoch 2/10\n",
      "3741/3741 [==============================] - 113s 30ms/step - loss: 1.1882 - val_loss: 1.1381\n",
      "Epoch 3/10\n",
      "3741/3741 [==============================] - 114s 30ms/step - loss: 1.1000 - val_loss: 1.0590\n",
      "Epoch 4/10\n",
      "3741/3741 [==============================] - 115s 31ms/step - loss: 1.0401 - val_loss: 1.0094\n",
      "Epoch 5/10\n",
      "3741/3741 [==============================] - 115s 31ms/step - loss: 1.0090 - val_loss: 0.9867\n",
      "Epoch 6/10\n",
      "3741/3741 [==============================] - 117s 31ms/step - loss: 0.9921 - val_loss: 0.9813\n",
      "Epoch 7/10\n",
      "3741/3741 [==============================] - 107s 28ms/step - loss: 0.9820 - val_loss: 0.9755\n",
      "Epoch 8/10\n",
      "3741/3741 [==============================] - 77s 21ms/step - loss: 0.9730 - val_loss: 0.9773\n",
      "Epoch 9/10\n",
      "3741/3741 [==============================] - 79s 21ms/step - loss: 0.9662 - val_loss: 0.9677\n",
      "Epoch 10/10\n",
      "3741/3741 [==============================] - 79s 21ms/step - loss: 0.9604 - val_loss: 0.9690\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Found untraced functions such as sci_net__tree_45_layer_call_and_return_conditional_losses, sci_net__tree_45_layer_call_fn, conv1d_483_layer_call_and_return_conditional_losses, conv1d_483_layer_call_fn, sci_block_45_layer_call_and_return_conditional_losses while saving (showing 5 of 1955). These functions will not be directly callable after loading.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: saved_models/model_learning_rate_0.0001/assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: saved_models/model_learning_rate_0.0001/assets\n"
     ]
    }
   ],
   "source": [
    "LEARNING_RATES = [0.1, 0.01, 0.001, 0.0001]\n",
    "\n",
    "train_losses = np.zeros((len(LEARNING_RATES), EPOCHS))\n",
    "val_losses = np.zeros((len(LEARNING_RATES), EPOCHS))\n",
    "for idx, LEARNING_RATE in enumerate(LEARNING_RATES):\n",
    "\n",
    "    model, history, X_train , y_train, X_val, y_val, X_test, y_test = train_scinet( X_train = results[\"X_train\"].astype('float32'),\n",
    "                                                                                    y_train = results[\"y_train\"].astype('float32'),\n",
    "                                                                                    X_val = results[\"X_val\"].astype('float32'),\n",
    "                                                                                    y_val = results[\"y_val\"].astype('float32'),\n",
    "                                                                                    X_test = results[\"X_test\"].astype('float32'),\n",
    "                                                                                    y_test = results[\"y_test\"].astype('float32'),\n",
    "                                                                                    epochs = EPOCHS,\n",
    "                                                                                    batch_size = BATCH_SIZE,\n",
    "                                                                                    X_LEN = X_LEN,\n",
    "                                                                                    Y_LEN = [Y_LEN],\n",
    "                                                                                    output_dim = [results[\"X_train\"].shape[2]],\n",
    "                                                                                    selected_columns = None,\n",
    "                                                                                    hid_size= HID_SIZE,\n",
    "                                                                                    num_levels= NUM_LEVELS,\n",
    "                                                                                    kernel = KERNEL_SIZE,\n",
    "                                                                                    dropout = DROPOUT,\n",
    "                                                                                    loss_weights= [1],\n",
    "                                                                                    learning_rate = LEARNING_RATE,\n",
    "                                                                                    probabilistic = PROBABILISTIC)\n",
    "\n",
    "    train_loss = history.history['loss']\n",
    "    train_losses[idx] = train_loss\n",
    "\n",
    "    val_loss = history.history['val_loss']\n",
    "    val_losses[idx] = val_loss\n",
    "    \n",
    "    model.save(f'saved_models/model_learning_rate_{LEARNING_RATE}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Plotting"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here the performance of each model on the validation set is compared using a plot. The hyperparamer of the model with the lowest loss in the validation set can be selected as the optimal value."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'utils.plotting'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "\u001b[0;32m/var/folders/45/tkfph_d93ss1d6wmks7ggsg00000gn/T/ipykernel_65006/87258678.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0mutils\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mplotting\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mplot_barplot\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0mhyperparameter_type\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'LearningRate'\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'utils.plotting'"
     ]
    }
   ],
   "source": [
    "\n",
    "from utils.plotting import plot_barplot\n",
    "\n",
    "\n",
    "hyperparameter_type='LearningRate'\n",
    "\n",
    "\n",
    "\n",
    "plot_barplot(LEARNING_RATES, val_losses, hyperparameter_type)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.12"
  },
  "vscode": {
   "interpreter": {
    "hash": "e0d398e7c3cc3d2b8386dfea47f5eae3378d5d39db7e2c8ef87e93246db0bfd2"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
